{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is in this file:\n",
    "# Cell 2: the imports that would need to be included\n",
    "# Cell 3: an existing code block provided for you to train the machine learning model, test the machine learning model, and see the results\n",
    "# Cell 4: Challenge 1\n",
    "# Cell 5: Challenge 2\n",
    "# Cell 6: Challenge 3\n",
    "# Cell 7: Challenge 4\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('week11_training_data_4Participants.csv', header=None)\n",
    "df_testing = pd.read_csv('week11_testing_data_2Participants.csv', header=None)\n",
    "\n",
    "y_train = df_training[9].values\n",
    "# Labels should start from 0 in sklearn\n",
    "y_train = y_train - 1\n",
    "df_training = df_training.drop([9], axis=1)\n",
    "X_train = df_training.values\n",
    "\n",
    "y_test = df_testing[9].values\n",
    "y_test = y_test - 1\n",
    "df_testing = df_testing.drop([9], axis=1)\n",
    "X_test = df_testing.values\n",
    "\n",
    "# Feature normalization for improving the performance of machine learning models. In this example code, \n",
    "# StandardScaler is used to scale original feature to be centered around zero. You could try other normalization methods.\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build KNN classifier, in this example code\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation. when we train a machine learning model on training set, we should evaluate its performance on testing set.\n",
    "# We could evaluate the model by different metrics. Firstly, we could calculate the classification accuracy. In this example\n",
    "# code, when n_neighbors is set to 4, the accuracy achieves 0.757.\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "# We could use confusion matrix to view the classification for each activity.\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity values: 1 – Sitting, 2 – Lying down, 3 – Standing, 4 – Washing Dishes, 5 – Vacuuming, \n",
    "# 6 – Sweeping, 7 – Walking outside, 8 – Ascending stairs, 9 – Descending stairs, 10 – Treadmill running, 11 – Bicycling, 12 – Bicycling (more intense), 13 – Rope Jumping.\n",
    "\n",
    "# Cell 4: Challenge 1\n",
    "# Can you interpret the confusion matrix above?\n",
    "# what are the rows and what are the columns?\n",
    "# which activity the machine learning predicts best?\n",
    "# which activity the machine learning predicts worst?\n",
    "\n",
    "#write your answers below for tutors to check\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Challenge 2\n",
    "# What issues you found for the given code?\n",
    "# Can you improve by providng the code in here?\n",
    "\n",
    "#write your answers and refined code below for tutors to check\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Challenge 3\n",
    "# What issues you found for the two python codes for creating training data and testing data?\n",
    "# Can you improve by providng the code in here and show the code to generate the required training and testing data?\n",
    "\n",
    "\n",
    "#write your answers and refined code below for tutors to check\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Challenge 4\n",
    "# This is the grand challenge\n",
    "# How to improve the prediction accuracy? Are there anything missing from the feature dataset?\n",
    "# Can you improve by showing the code to improve the accuracy?\n",
    "\n",
    "#Hint:\n",
    "#Wrist measurements\n",
    "#•\tColumn index 0, 1, 2 – Accelerometer (axis 1, 2, 3)\n",
    "#•\tColumn index 3, 4, 5 – Gyroscope (axis 1, 2, 3)\n",
    "#Chest measurements\n",
    "#•\tColumn index 6, 7, 8 – Accelerometer (axis 1, 2, 3)\n",
    "#•\tColumn index 9, 10, 11 – Gyroscope (axis 1, 2, 3)\n",
    "#Hip measurements\n",
    "#•\tColumn index 12, 13, 14 – Accelerometer (axis 1, 2, 3)\n",
    "#•\tColumn index 15, 16, 17 – Gyroscope (axis 1, 2, 3)\n",
    "#Ankle measurements\n",
    "#•\tColumn index 18, 19, 20 – Accelerometer (axis 1, 2, 3)\n",
    "#•\tColumn index 21, 22, 23 – Gyroscope (axis 1, 2, 3)\n",
    "#. YOU NEED TO CHANGE BOTH feature dataset and model training parts\n",
    "\n",
    "\n",
    "# MORE HINT #\n",
    "####.  The first part for feature dataset  #####\n",
    "\n",
    "##################\n",
    "\n",
    "\n",
    "# Only the first Accelerometer is used, that is why!!!\n",
    "  #THIS NEEDS TO BE CHANGED!!!!! how many columns will be in the feature set?\n",
    "     # feature_set = np.empty(shape=(0, 10))\n",
    "        \n",
    "        \n",
    "    \n",
    "#  #THIS NEEDS TO BE CHANGED!!!!! what shall be the range value?\n",
    "#                for i in range(3):\n",
    "#                    feature_sample.append(np.min(sample_data[:, i]))\n",
    "#                    feature_sample.append(np.max(sample_data[:, i]))\n",
    " #                   feature_sample.append(np.mean(sample_data[:, i]))\n",
    "    \n",
    "    #write your first part code below for tutors to check\n",
    "\n",
    "\n",
    "\n",
    "####.  The second part for model training #####\n",
    "# This needs to be changed ->     df_training = df_training.drop([9], axis=1)\n",
    "# 9 shall be hardcoded???\n",
    "# How many features will be?  each sensor will have 3 features Min, Max, Mean\n",
    "# If you get this part working, what is the accuracy now? Does it improved?  If so, how much?\n",
    "# Activity values: 1 – Sitting, 2 – Lying down, 3 – Standing, 4 – Washing Dishes, 5 – Vacuuming, \n",
    "# 6 – Sweeping, 7 – Walking outside, 8 – Ascending stairs, 9 – Descending stairs, 10 – Treadmill running, 11 – Bicycling, 12 – Bicycling (more intense), 13 – Rope Jumping.\n",
    "\n",
    "    #write your second part code below for tutors to check, output the new prediction results, and analyse the updated prediction results\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint for next week -> The Finale\n",
    "# as you can see, after all those efforts we still have a few actitivites with prediction errors\n",
    "# We will cover it more in the Finale week"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
